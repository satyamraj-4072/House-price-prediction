# -*- coding: utf-8 -*-
"""House price Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fIAPaytRB9VYGjZW-cAoRiQ1EHIneXlD

# **House Price Prediction**

Predicting house prices can help to determine the selling price of a house of a particular region and can help people to find the right time to buy a home.
Now, I will take you through a machine learning project on House Price prediction with Python. Let’s start by importing the necessary Python libraries and the dataset.

**Data Analysis**

Importing necessary libraries
"""

# Commented out IPython magic to ensure Python compatibility.
#loading need libraries
import numpy as np
import seaborn as sns
import pandas as pd
import matplotlib.pyplot as plt
from scipy import stats
# %matplotlib inline

train = pd.read_csv('/content/train.csv')

train.head()

"""Shape of train data."""

train.shape

"""By implemanting the information data set using the info() command  which is useful for getting a quick description of the data, especially the total number of rows and the type of each attribute."""

train.info()

"""# Target variable
## Analysis on target variable

By using target variable we can understand the feature of dataset clearly.
"""

plt.subplots(figsize=(12,9))
sns.distplot(train['SalePrice'], fit=stats.norm)

(mu, sigma) = stats.norm.fit(train['SalePrice'])

plt.legend(['Normal dist. ($\mu=$ {:.2f} and $\sigma=$ {:.2f} )'.format(mu, sigma)], loc='best')
plt.ylabel('Frequency')

fig = plt.figure()
stats.probplot(train['SalePrice'], plot=plt)
plt.show()

"""Target varibale is right skewed.

# **We use log for target variable to make more normal distribution of the variable.**

Before creating a machine learning model for house price prediction with Python let’s visualize the data in terms of SalePrice and Frequency.
"""

train['SalePrice'] = np.log1p(train['SalePrice'])

plt.subplots(figsize=(12,9))
sns.distplot(train['SalePrice'], fit=stats.norm)

(mu, sigma) = stats.norm.fit(train['SalePrice'])

plt.legend(['Normal dist. ($\mu=$ {:.2f} and $\sigma=$ {:.2f} )'.format(mu, sigma)], loc='best')
plt.ylabel('Frequency')

fig = plt.figure()
stats.probplot(train['SalePrice'], plot=plt)
plt.show()

"""Checking the missing values of the data set"""

train.columns[train.isnull().any()]

"""Plot of missing values"""

plt.figure(figsize=(12, 6))
sns.heatmap(train.isnull(), cmap="Greens")
plt.show()

"""Counts of missing values in each of the columns"""

Isnull = train.isnull().sum()/len(train)*100
Isnull = Isnull[Isnull>0]
Isnull.sort_values(inplace=True, ascending=False)
Isnull

"""**Correlation between train attributes**



"""

#Separate variable into new dataframe from original dataframe which has only numerical values
#there is 38 numerical attribute from 81 attributes
train_corr = train.select_dtypes(include=[np.number])

train_corr.shape

#Delete Id because that is not need for corralation plot
del train_corr['Id']

#Coralation plot
corr = train_corr.corr()
plt.subplots(figsize=(20,9),)
sns.heatmap(corr, annot=True, cmap="YlGnBu")

#unique value of OverallQual
train.OverallQual.unique()

# PoolQC has missing value ratio is 99%+. So, there is fill by None
train['PoolQC'] = train['PoolQC'].fillna('None')

#Arround 50% missing values attributes have been fill by None
train['MiscFeature'] = train['MiscFeature'].fillna('None')
train['Alley'] = train['Alley'].fillna('None')
train['Fence'] = train['Fence'].fillna('None')
train['FireplaceQu'] = train['FireplaceQu'].fillna('None')

#Group by neighborhood and fill in missing value by the median LotFrontage of all the neighborhood
train['LotFrontage'] = train.groupby("Neighborhood")["LotFrontage"].transform(
    lambda x: x.fillna(x.median()))

#GarageType, GarageFinish, GarageQual and GarageCond these are replacing with None
for col in ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']:
    train[col] = train[col].fillna('None')

#GarageYrBlt, GarageArea and GarageCars these are replacing with zero
for col in ['GarageYrBlt', 'GarageArea', 'GarageCars']:
    train[col] = train[col].fillna(int(0))

#BsmtFinType2, BsmtExposure, BsmtFinType1, BsmtCond, BsmtQual these are replacing with None
for col in ('BsmtFinType2', 'BsmtExposure', 'BsmtFinType1', 'BsmtCond', 'BsmtQual'):
    train[col] = train[col].fillna('None')

#MasVnrArea : replace with zero
train['MasVnrArea'] = train['MasVnrArea'].fillna(int(0))

#MasVnrType : replace with None
train['MasVnrType'] = train['MasVnrType'].fillna('None')

#There is put mode value 
train['Electrical'] = train['Electrical'].fillna(train['Electrical']).mode()[0]

#Checking there is any null value or not
plt.figure(figsize=(10, 5))
sns.heatmap(train.isnull(), cmap="Greens")

"""Now, there is no any missing values

## **Encoding string to integer**
"""

cols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', 
        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', 
        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',
        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', 
        'YrSold', 'MoSold', 'MSZoning', 'LandContour', 'LotConfig', 'Neighborhood',
        'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',
        'Exterior2nd', 'MasVnrType', 'MasVnrArea', 'Foundation', 'GarageType', 'MiscFeature', 
        'SaleType', 'SaleCondition', 'Electrical', 'Heating')

from sklearn.preprocessing import LabelEncoder
for c in cols:
    lbl = LabelEncoder() 
    lbl.fit(list(train[c].values)) 
    train[c] = lbl.transform(list(train[c].values))

"""# **Prepraring data for prediction**"""

# Split data into train and test formate
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)

"""# Linear Regression

Now I will use the linear regression algorithm for the task of house price prediction with Python.
"""

#Train the model
from sklearn import linear_model
model = linear_model.LinearRegression()

#Fit the model
model.fit(X_train, y_train)

#Prediction
print("Predict value " + str(model.predict([X_test[142]])))
print("Real value " + str(y_test[142]))

#Score/Accuracy
print("Accuracy --> ", model.score(X_test, y_test)*100)

"""# RandomForest Regression"""

#Train the model
from sklearn.ensemble import RandomForestRegressor
model = RandomForestRegressor(n_estimators=1000)

#Fit
model.fit(X_train, y_train)

#Score/Accuracy
print("Accuracy --> ", model.score(X_test, y_test)*100)

"""# GradientBoostingRegressor"""

#Train the model
from sklearn.ensemble import GradientBoostingRegressor
GBR = GradientBoostingRegressor(n_estimators=100, max_depth=4)

#Fit
GBR.fit(X_train, y_train)

print("Accuracy --> ", GBR.score(X_test, y_test)*100)